{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dependencies\n",
    "from bs4 import BeautifulSoup\n",
    "from splinter import Browser\n",
    "import pandas as pd\n",
    "import time\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating a path to open a browser\n",
    "executable_path = {'executable_path': 'chromedriver.exe'}\n",
    "browser = Browser('chrome', **executable_path, headless=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Connect to a url for NASA's Mars website\n",
    "url = \"https://mars.nasa.gov/news\"\n",
    "browser.visit(url)\n",
    "time.sleep(1)\n",
    "\n",
    "# Create a Beautiful Soup object\n",
    "html = browser.html\n",
    "soup = BeautifulSoup(html, 'html.parser')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scrape Latest article title and teaser on NASA's Mars website\n",
    "news_title = soup.find('div', class_='content_title').text\n",
    "news_p = soup.find('div', class_='article_teaser_body').text\n",
    "print(news_title)\n",
    "print(news_p)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Connect to a url to grab NASA's featured Mars image\n",
    "url_jpl = \"https://www.jpl.nasa.gov/spaceimages/?search=&category=Mars\"\n",
    "browser.visit(url_jpl)\n",
    "time.sleep(1)\n",
    "\n",
    "# Create a Beautiful Soup object\n",
    "html = browser.html\n",
    "soup = BeautifulSoup(html, 'html.parser')\n",
    "\n",
    "# Navigate to the page to scrape the full size featured image\n",
    "browser.click_link_by_partial_text('Full')\n",
    "time.sleep(1)\n",
    "url_jpl2 = 'https://www.jpl.nasa.gov' + soup.find('a', class_='button')['data-link']\n",
    "browser.visit(url_jpl2)\n",
    "time.sleep(1)\n",
    "html = browser.html\n",
    "soup = BeautifulSoup(html, 'html.parser')\n",
    "featured_image_url = 'https://www.jpl.nasa.gov' + soup.find('figure', class_='lede').a['href']\n",
    "print(featured_image_url)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Connect to url for Mars Weather Twitter page\n",
    "url_mars_twitter = \"https://twitter.com/marswxreport?lang=en\"\n",
    "browser.visit(url_mars_twitter)\n",
    "time.sleep(1)\n",
    "\n",
    "# Create a Beautiful Soup object\n",
    "html = browser.html\n",
    "soup = BeautifulSoup(html, 'html.parser')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scrape the latest weather from Mars\n",
    "mars_weather = soup.find('p', class_='TweetTextSize').text\n",
    "print(mars_weather)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Connect to url for Mars facts page\n",
    "url_mars_facts = \"https://space-facts.com/mars/\"\n",
    "\n",
    "# Use pandas to scrape the table of Mars facts\n",
    "mars_facts = pd.read_html(url_mars_facts)\n",
    "\n",
    "# Turn the table into a Dataframe\n",
    "mars_facts_df = mars_facts[0]\n",
    "mars_facts_df.columns = ['Description', 'Value']\n",
    "mars_facts_df.set_index('Description', inplace=True)\n",
    "\n",
    "# Store the table as html\n",
    "mars_facts_html = mars_facts_df.to_html(justify='left')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Connect to url for Mars hemisphere images (Using the archive website since the actual one is down)\n",
    "url_mars_hemisphere = \"http://web.archive.org/web/20181114171728/https://astrogeology.usgs.gov/search/results?q=hemisphere+enhanced&k1=target&v1=Mars\"\n",
    "browser.visit(url_mars_hemisphere)\n",
    "time.sleep(1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scrape the images of each hemisphere\n",
    "hemisphere_image_urls = []\n",
    "hemispheres = ['Cerberus', 'Schiaparelli', 'Syrtis Major', 'Valles Marineris']\n",
    "\n",
    "# Loop through the four pages containing the information\n",
    "for hemisphere in hemispheres:\n",
    "    browser.click_link_by_partial_text(hemisphere)\n",
    "    time.sleep(1)\n",
    "    html = browser.html\n",
    "    soup = BeautifulSoup(html, 'html.parser')\n",
    "    title = soup.find('h2', class_='title').text\n",
    "    img_url = 'https://web.archive.org/' + soup.find('img', class_='wide-image')['src']\n",
    "    hemisphere_image_urls.append({'title': title, 'img_url': img_url})\n",
    "    browser.back()\n",
    "    time.sleep(1)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hemisphere_image_urls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "browser.quit()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 36 (PythonData)",
   "language": "python",
   "name": "pythondata"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
